{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "brutal-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ideal-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "acute-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import scipy.io\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import math\n",
    "from skimage import io, transform\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import shutil\n",
    "import codecs \n",
    "import timeit\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import progressbar\n",
    "%matplotlib inline\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import gc\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "friendly-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(path):    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "    fc = 0\n",
    "    ret = True\n",
    "    while (fc < frameCount  and ret):\n",
    "        ret, buf[fc] = cap.read()\n",
    "        fc += 1\n",
    "    cap.release()\n",
    "    return buf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "through-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(buf):\n",
    "    feature_buf = []\n",
    "    for i  in range(len(buf)):\n",
    "      feature_buf.append(buf[i].mean(axis=0).mean(axis=0))\n",
    "    return feature_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "engaging-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_frames(buf,feature_buf,threshold):\n",
    "    key_frame = []\n",
    "    key_frame.append(buf[0])\n",
    "    i = 0\n",
    "    while i < (len(buf)):\n",
    "        for j in range(i+1,len(buf)):\n",
    "            mse = np.mean((feature_buf[i] - feature_buf[j])**2)\n",
    "            if mse > threshold:\n",
    "                key_frame.append(buf[j])\n",
    "                i = j\n",
    "                break\n",
    "        i = i+1   \n",
    "    return key_frame   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "informed-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizer(video_array):    \n",
    "    plt.ion()\n",
    "    for i in range(len(video_array)):\n",
    "        plt.imshow(cv2.cvtColor(video_array[i], cv2.COLOR_BGR2RGB))\n",
    "        #plt.show()\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "legal-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(key_f_input,key_f_existing,\n",
    "               threshold_match,threshold_compare): # threshold_match :: ratio threthold\n",
    "                                                # threshold_compare :: feature compare threshold\n",
    "    feature_buf_input = get_feature_vector(key_f_input)\n",
    "    feature_buf_existing = get_feature_vector(key_f_existing)\n",
    "    match_flag = False\n",
    "    counter = 0\n",
    "    for i in range(len(key_f_input)): # elli bn3ml 3leh retrieval\n",
    "        for j in range(len(key_f_existing)): # wa7ed mn el database\n",
    "            mse = np.mean((feature_buf_existing[i] - feature_buf_input[j])**2)\n",
    "            if mse<threshold_compare:\n",
    "                counter = counter + 1\n",
    "                break\n",
    "    ratio_input = counter/len(key_f_input) # ratio of input video key frames to counter\n",
    "    ratio_existing = counter/len(key_f_existing) # ratio of existing video key frames to counter\n",
    "    ratio_maximum = max(ratio_input,ratio_existing) # the highest ratio \n",
    "    if ratio_maximum >= threshold_match:\n",
    "        match_flag = True\n",
    "    return match_flag    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "passive-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = 'cbvrs3.mp4'\n",
    "buf0 = capture(path0)\n",
    "threshold_key_frame = 1\n",
    "buf_feature0 =  get_feature_vector(buf0)\n",
    "key_f0 = get_key_frames(buf0,buf_feature0,threshold_key_frame)\n",
    "\n",
    "path1 = 'cbvrs4.mp4'\n",
    "buf1 = capture(path1)\n",
    "buf_feature1 =  get_feature_vector(buf1)\n",
    "key_f1 = get_key_frames(buf1,buf_feature1,threshold_key_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "collected-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer(key_f1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "nutritional-beads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_similar(key_f1,key_f0,0.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-greek",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
